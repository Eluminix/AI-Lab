{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Download NLTK resources (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "318efdc746f40f7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data and Models",
   "id": "85db100187bbfb2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load CSV with all pairs\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "\n",
    "# Paths to multilingual FastText aligned vectors (.vec files)\n",
    "fasttext_model_paths = {\n",
    "    'en': 'pretrained_models/fasttext/wiki.en.align.vec',\n",
    "    'es': 'pretrained_models/fasttext/wiki.es.align.vec',\n",
    "    'de': 'pretrained_models/fasttext/wiki.de.align.vec',\n",
    "    'pl': 'pretrained_models/fasttext/wiki.pl.align.vec',\n",
    "    'tr': 'pretrained_models/fasttext/wiki.tr.align.vec',\n",
    "    'ar': 'pretrained_models/fasttext/wiki.ar.align.vec',\n",
    "    'fr': 'pretrained_models/fasttext/wiki.fr.align.vec'\n",
    "}\n",
    "\n",
    "# Load and cache gensim models\n",
    "fasttext_models = {}\n",
    "for lang, path in fasttext_model_paths.items():\n",
    "    print(f\"Loading FastText model for {lang}...\")\n",
    "    fasttext_models[lang] = KeyedVectors.load_word2vec_format(path)"
   ],
   "id": "47a9f78d29bfbc89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing + Embeddings",
   "id": "3ae08f6bcc1509d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simple_preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    return word_tokenize(text.lower())"
   ],
   "id": "b24c043953c386a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def average_embedding(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ],
   "id": "396d9bb835f66f58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extractors",
   "id": "d024a84590f8c37b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_features_lang_aware(feature_func):\n",
    "    def wrapped(row):\n",
    "        lang = row['lang1']\n",
    "        model = fasttext_models.get(lang)\n",
    "        if model is None:\n",
    "            raise ValueError(f\"No model found for language: {lang}\")\n",
    "        return feature_func(row, model)\n",
    "    return wrapped\n",
    "\n",
    "def extract_title_features(row, model_dict):\n",
    "    tokens1 = simple_preprocess(row['title1'])\n",
    "    tokens2 = simple_preprocess(row['title2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model_dict)\n",
    "    vec2 = average_embedding(tokens2, model_dict)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_text_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['text1'])\n",
    "    tokens2 = simple_preprocess(row['text2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_combined_features(row, model):\n",
    "    t1 = f\"{row['title1']} {row['text1']}\"\n",
    "    t2 = f\"{row['title2']} {row['text2']}\"\n",
    "    tokens1 = simple_preprocess(t1)\n",
    "    tokens2 = simple_preprocess(t2)\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_all_features(row, model):\n",
    "    structured_cols = ['geography', 'entities', 'time', 'narrative', 'style', 'tone']\n",
    "    # --- Title vector ---\n",
    "    tokens_title1 = simple_preprocess(row['title1'])\n",
    "    tokens_title2 = simple_preprocess(row['title2'])\n",
    "    vec_title1 = average_embedding(tokens_title1, model)\n",
    "    vec_title2 = average_embedding(tokens_title2, model)\n",
    "    sim_title = cosine_similarity([vec_title1], [vec_title2])[0][0]\n",
    "    diff_title = np.abs(vec_title1 - vec_title2)\n",
    "    prod_title = vec_title1 * vec_title2\n",
    "\n",
    "    # --- Text vector ---\n",
    "    tokens_text1 = simple_preprocess(row['text1'])\n",
    "    tokens_text2 = simple_preprocess(row['text2'])\n",
    "    vec_text1 = average_embedding(tokens_text1, model)\n",
    "    vec_text2 = average_embedding(tokens_text2, model)\n",
    "    sim_text = cosine_similarity([vec_text1], [vec_text2])[0][0]\n",
    "    diff_text = np.abs(vec_text1 - vec_text2)\n",
    "    prod_text = vec_text1 * vec_text2\n",
    "\n",
    "    # --- Structured features ---\n",
    "    structured = [row[col] for col in structured_cols]\n",
    "\n",
    "    # --- Final feature vector ---\n",
    "    return (\n",
    "        [sim_title] + diff_title.tolist() + prod_title.tolist() +\n",
    "        [sim_text] + diff_text.tolist() + prod_text.tolist() +\n",
    "        structured\n",
    "    )\n"
   ],
   "id": "11c2fa22f65f95f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Train/Evaluate Function",
   "id": "7870fffc5a77d2be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_classification(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "\n",
    "    # Extract features\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall_classification\"])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - {description}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ],
   "id": "80ab4ce437630b74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Train/Evaluate",
   "id": "7c74b57e282eb89a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_regression(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall\"])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbm', LGBMRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "    print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    }"
   ],
   "id": "51bfc62a88bd058"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with FastText",
   "id": "d36a3f8e04fc870d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = []\n",
    "\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_title_features), None, \"Title Only - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_text_features), None, \"Text Only - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_combined_features), None, \"Title + Text - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_all_features), None, \"All Features - Classification\"))\n"
   ],
   "id": "788a7fd4c1c2f845"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with FastText",
   "id": "bcc8e2897c5271b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results.append(run_regression(df, extract_features_lang_aware(extract_title_features), None, \"Title Only - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_text_features), None, \"Text Only - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_combined_features), None, \"Title + Text - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_all_features), None, \"All Features - Regression\"))"
   ],
   "id": "a73be86e03a1fa90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FastText Classification vs. Regression",
   "id": "26202a63a242cbb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "e31ee8415fc3662"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
