{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:36:37.004563Z",
     "start_time": "2025-05-29T16:36:36.998968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Download NLTK resources (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "97729a05ab6db2b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/i538819/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/i538819/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing + Embeddings",
   "id": "2c99e857b75949e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:23:02.892872Z",
     "start_time": "2025-05-29T16:23:02.890696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simple_preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    return word_tokenize(text.lower())"
   ],
   "id": "f73e3eb05b657a1d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:23:02.911488Z",
     "start_time": "2025-05-29T16:23:02.909678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def average_embedding(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ],
   "id": "aa7db70015d81b1a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extractors",
   "id": "d91b3b1d1b45dc16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:23:02.918994Z",
     "start_time": "2025-05-29T16:23:02.914321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_title_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['title1'])\n",
    "    tokens2 = simple_preprocess(row['title2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_text_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['text1'])\n",
    "    tokens2 = simple_preprocess(row['text2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_combined_features(row, model):\n",
    "    t1 = f\"{row['title1']} {row['text1']}\"\n",
    "    t2 = f\"{row['title2']} {row['text2']}\"\n",
    "    tokens1 = simple_preprocess(t1)\n",
    "    tokens2 = simple_preprocess(t2)\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_all_features(row, model):\n",
    "    structured_cols = ['geography', 'entities', 'time', 'narrative', 'style', 'tone']\n",
    "    # --- Title vector ---\n",
    "    tokens_title1 = simple_preprocess(row['title1'])\n",
    "    tokens_title2 = simple_preprocess(row['title2'])\n",
    "    vec_title1 = average_embedding(tokens_title1, model)\n",
    "    vec_title2 = average_embedding(tokens_title2, model)\n",
    "    sim_title = cosine_similarity([vec_title1], [vec_title2])[0][0]\n",
    "    diff_title = np.abs(vec_title1 - vec_title2)\n",
    "    prod_title = vec_title1 * vec_title2\n",
    "\n",
    "    # --- Text vector ---\n",
    "    tokens_text1 = simple_preprocess(row['text1'])\n",
    "    tokens_text2 = simple_preprocess(row['text2'])\n",
    "    vec_text1 = average_embedding(tokens_text1, model)\n",
    "    vec_text2 = average_embedding(tokens_text2, model)\n",
    "    sim_text = cosine_similarity([vec_text1], [vec_text2])[0][0]\n",
    "    diff_text = np.abs(vec_text1 - vec_text2)\n",
    "    prod_text = vec_text1 * vec_text2\n",
    "\n",
    "    # --- Structured features ---\n",
    "    structured = [row[col] for col in structured_cols]\n",
    "\n",
    "    # --- Final feature vector ---\n",
    "    return (\n",
    "        [sim_title] + diff_title.tolist() + prod_title.tolist() +\n",
    "        [sim_text] + diff_text.tolist() + prod_text.tolist() +\n",
    "        structured\n",
    "    )\n"
   ],
   "id": "53e9854a04ef11fb",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Train/Evaluate Function",
   "id": "56a121eefbc606e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:23:02.929483Z",
     "start_time": "2025-05-29T16:23:02.926575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_classification(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "\n",
    "    # Extract features\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall_classification\"])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ],
   "id": "c6235e1708dca4eb",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with Word2Vec",
   "id": "53b4021c26f50837"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:23:47.956666Z",
     "start_time": "2025-05-29T16:23:02.936991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CSV with all pairs\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "\n",
    "# Load pre-trained Word2Vec model (Google News vectors)\n",
    "print(\"Loading Word2Vec model ...\")\n",
    "model = KeyedVectors.load_word2vec_format(\"pretrained_models/word2vec/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(run_classification(df, extract_title_features, model, \"Title Only - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_text_features, model, \"Text Only - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_combined_features, model, \"Title + Text - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_all_features, model, \"All Features - Word2Vec\"))\n"
   ],
   "id": "8070abecd3b50518",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV...\n",
      "Loading Word2Vec model ...\n",
      "\n",
      "=== Running classification on: Title Only - Word2Vec ===\n",
      "Accuracy: 0.495\n",
      "Precision: 0.421\n",
      "Recall: 0.495\n",
      "F1 Score: 0.393\n",
      "\n",
      "=== Running classification on: Text Only - Word2Vec ===\n",
      "Accuracy: 0.502\n",
      "Precision: 0.450\n",
      "Recall: 0.502\n",
      "F1 Score: 0.432\n",
      "\n",
      "=== Running classification on: Title + Text - Word2Vec ===\n",
      "Accuracy: 0.509\n",
      "Precision: 0.429\n",
      "Recall: 0.509\n",
      "F1 Score: 0.435\n",
      "\n",
      "=== Running classification on: All Features - Word2Vec ===\n",
      "Accuracy: 0.648\n",
      "Precision: 0.604\n",
      "Recall: 0.648\n",
      "F1 Score: 0.575\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with FastText",
   "id": "8e3b9f8972daaa84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:24:25.375453Z",
     "start_time": "2025-05-29T16:23:47.966528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load FastText word vectors\n",
    "print(\"Loading FastText model...\")\n",
    "if os.path.exists(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\"):\n",
    "    model2 = KeyedVectors.load(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\")  # faster loading\n",
    "else:\n",
    "    model2 = KeyedVectors.load_word2vec_format(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.vec\")\n",
    "    model2.save(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\")\n",
    "\n",
    "results.append(run_classification(df, extract_title_features, model2, \"Title Only - FastText\"))\n",
    "results.append(run_classification(df, extract_text_features, model2, \"Text Only - FastText\"))\n",
    "results.append(run_classification(df, extract_combined_features, model2, \"Title + Text - FastText\"))\n",
    "results.append(run_classification(df, extract_all_features, model2, \"All Features - FastText\"))\n"
   ],
   "id": "d65a443e7ef95f52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV...\n",
      "Loading FastText model...\n",
      "\n",
      "=== Running classification on: Title Only - FastText ===\n",
      "Accuracy: 0.462\n",
      "Precision: 0.455\n",
      "Recall: 0.462\n",
      "F1 Score: 0.370\n",
      "\n",
      "=== Running classification on: Text Only - FastText ===\n",
      "Accuracy: 0.474\n",
      "Precision: 0.412\n",
      "Recall: 0.474\n",
      "F1 Score: 0.387\n",
      "\n",
      "=== Running classification on: Title + Text - FastText ===\n",
      "Accuracy: 0.465\n",
      "Precision: 0.374\n",
      "Recall: 0.465\n",
      "F1 Score: 0.382\n",
      "\n",
      "=== Running classification on: All Features - FastText ===\n",
      "Accuracy: 0.646\n",
      "Precision: 0.604\n",
      "Recall: 0.646\n",
      "F1 Score: 0.584\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Word2Vec vs. FastText",
   "id": "1bfa31e1531ea08b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:24:25.390795Z",
     "start_time": "2025-05-29T16:24:25.382546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "196b613f0b1a989b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Table ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     Model  Accuracy  Precision    Recall  F1 Score\n",
       "7  All Features - FastText  0.645985   0.603655  0.645985  0.583773\n",
       "3  All Features - Word2Vec  0.647810   0.603832  0.647810  0.575179\n",
       "5     Text Only - FastText  0.474453   0.412076  0.474453  0.387133\n",
       "1     Text Only - Word2Vec  0.501825   0.449954  0.501825  0.432290\n",
       "6  Title + Text - FastText  0.465328   0.373650  0.465328  0.382304\n",
       "2  Title + Text - Word2Vec  0.509124   0.429039  0.509124  0.434609\n",
       "4    Title Only - FastText  0.461679   0.455205  0.461679  0.369650\n",
       "0    Title Only - Word2Vec  0.494526   0.420845  0.494526  0.393191"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All Features - FastText</td>\n",
       "      <td>0.645985</td>\n",
       "      <td>0.603655</td>\n",
       "      <td>0.645985</td>\n",
       "      <td>0.583773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Features - Word2Vec</td>\n",
       "      <td>0.647810</td>\n",
       "      <td>0.603832</td>\n",
       "      <td>0.647810</td>\n",
       "      <td>0.575179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Text Only - FastText</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.412076</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.387133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text Only - Word2Vec</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.449954</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.432290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title + Text - FastText</td>\n",
       "      <td>0.465328</td>\n",
       "      <td>0.373650</td>\n",
       "      <td>0.465328</td>\n",
       "      <td>0.382304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title + Text - Word2Vec</td>\n",
       "      <td>0.509124</td>\n",
       "      <td>0.429039</td>\n",
       "      <td>0.509124</td>\n",
       "      <td>0.434609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title Only - FastText</td>\n",
       "      <td>0.461679</td>\n",
       "      <td>0.455205</td>\n",
       "      <td>0.461679</td>\n",
       "      <td>0.369650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title Only - Word2Vec</td>\n",
       "      <td>0.494526</td>\n",
       "      <td>0.420845</td>\n",
       "      <td>0.494526</td>\n",
       "      <td>0.393191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Train/Evaluate",
   "id": "9972106b2da16e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:36:26.158966Z",
     "start_time": "2025-05-29T16:36:26.155208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_regression(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model))\n",
    "        y.append(row[\"overall\"])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "    print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    }"
   ],
   "id": "dc1640d51dcfbcda",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with Word2Vec",
   "id": "d9f89fb38ab15bde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:42:27.447625Z",
     "start_time": "2025-05-29T16:36:40.952641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regression_results = []\n",
    "\n",
    "regression_results.append(run_regression(df, extract_title_features, model, \"Title Only - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_text_features, model, \"Text Only - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_combined_features, model, \"Title + Text - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_all_features, model, \"All Features - Word2Vec\"))"
   ],
   "id": "90bd13151cfeb76e",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with FastText",
   "id": "9d28a46695645021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:51:45.612983Z",
     "start_time": "2025-05-29T16:42:27.460749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regression_results.append(run_regression(df, extract_title_features, model2, \"Title Only - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_text_features, model2, \"Text Only - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_combined_features, model2, \"Title + Text - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_all_features, model2, \"All Features - FastText\"))"
   ],
   "id": "a3c08ace2e7f18ef",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Word2Vec vs. FastText",
   "id": "dbac77e435914bb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:51:45.637011Z",
     "start_time": "2025-05-29T16:51:45.632346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to DataFrame\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "display(regression_results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "58d11aa4ff9b344b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Model       MSE       MAE        R2\n",
       "7  All Features - FastText  0.122478  0.243315  0.903296\n",
       "3  All Features - Word2Vec  0.121569  0.243221  0.904014\n",
       "5     Text Only - FastText  1.001779  0.865538  0.209030\n",
       "1     Text Only - Word2Vec  0.840912  0.757486  0.336045\n",
       "6  Title + Text - FastText  0.981165  0.858487  0.225306\n",
       "2  Title + Text - Word2Vec  0.831305  0.748981  0.343631\n",
       "4    Title Only - FastText  1.095470  0.911488  0.135055\n",
       "0    Title Only - Word2Vec  0.955125  0.822876  0.245867"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All Features - FastText</td>\n",
       "      <td>0.122478</td>\n",
       "      <td>0.243315</td>\n",
       "      <td>0.903296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Features - Word2Vec</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.243221</td>\n",
       "      <td>0.904014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Text Only - FastText</td>\n",
       "      <td>1.001779</td>\n",
       "      <td>0.865538</td>\n",
       "      <td>0.209030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text Only - Word2Vec</td>\n",
       "      <td>0.840912</td>\n",
       "      <td>0.757486</td>\n",
       "      <td>0.336045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title + Text - FastText</td>\n",
       "      <td>0.981165</td>\n",
       "      <td>0.858487</td>\n",
       "      <td>0.225306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title + Text - Word2Vec</td>\n",
       "      <td>0.831305</td>\n",
       "      <td>0.748981</td>\n",
       "      <td>0.343631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title Only - FastText</td>\n",
       "      <td>1.095470</td>\n",
       "      <td>0.911488</td>\n",
       "      <td>0.135055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title Only - Word2Vec</td>\n",
       "      <td>0.955125</td>\n",
       "      <td>0.822876</td>\n",
       "      <td>0.245867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
