{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Download NLTK resources (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "28f7a842c8294982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing + Embeddings",
   "id": "32699b1633d7a53a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simple_preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    return word_tokenize(text.lower())"
   ],
   "id": "c265686cbbe69b54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def average_embedding(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ],
   "id": "fa24414f99eaa734"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extractors",
   "id": "16c234c0780d10e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_title_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['title1'])\n",
    "    tokens2 = simple_preprocess(row['title2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_text_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['text1'])\n",
    "    tokens2 = simple_preprocess(row['text2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_combined_features(row, model):\n",
    "    t1 = f\"{row['title1']} {row['text1']}\"\n",
    "    t2 = f\"{row['title2']} {row['text2']}\"\n",
    "    tokens1 = simple_preprocess(t1)\n",
    "    tokens2 = simple_preprocess(t2)\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_all_features(row, model):\n",
    "    structured_cols = ['geography', 'entities', 'time', 'narrative', 'style', 'tone']\n",
    "    # --- Title vector ---\n",
    "    tokens_title1 = simple_preprocess(row['title1'])\n",
    "    tokens_title2 = simple_preprocess(row['title2'])\n",
    "    vec_title1 = average_embedding(tokens_title1, model)\n",
    "    vec_title2 = average_embedding(tokens_title2, model)\n",
    "    sim_title = cosine_similarity([vec_title1], [vec_title2])[0][0]\n",
    "    diff_title = np.abs(vec_title1 - vec_title2)\n",
    "    prod_title = vec_title1 * vec_title2\n",
    "\n",
    "    # --- Text vector ---\n",
    "    tokens_text1 = simple_preprocess(row['text1'])\n",
    "    tokens_text2 = simple_preprocess(row['text2'])\n",
    "    vec_text1 = average_embedding(tokens_text1, model)\n",
    "    vec_text2 = average_embedding(tokens_text2, model)\n",
    "    sim_text = cosine_similarity([vec_text1], [vec_text2])[0][0]\n",
    "    diff_text = np.abs(vec_text1 - vec_text2)\n",
    "    prod_text = vec_text1 * vec_text2\n",
    "\n",
    "    # --- Structured features ---\n",
    "    structured = [row[col] for col in structured_cols]\n",
    "\n",
    "    # --- Final feature vector ---\n",
    "    return (\n",
    "        [sim_title] + diff_title.tolist() + prod_title.tolist() +\n",
    "        [sim_text] + diff_text.tolist() + prod_text.tolist() +\n",
    "        structured\n",
    "    )\n"
   ],
   "id": "affb0226cb47e2de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Train/Evaluate Function",
   "id": "8ba0578e309c5abc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_classification(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "\n",
    "    # Extract features\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall_classification\"])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - {description}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ],
   "id": "f05276e2ca518d00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with Word2Vec",
   "id": "7a4706e4333d62ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load CSV with all pairs\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "\n",
    "# Filter for English-only pairs\n",
    "df = df[(df[\"lang1\"] == \"en\") & (df[\"lang2\"] == \"en\")].reset_index(drop=True)\n",
    "\n",
    "# Load pre-trained Word2Vec model (Google News vectors)\n",
    "print(\"Loading Word2Vec model ...\")\n",
    "model = KeyedVectors.load_word2vec_format(\"pretrained_models/word2vec/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(run_classification(df, extract_title_features, model, \"Title Only - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_text_features, model, \"Text Only - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_combined_features, model, \"Title + Text - Word2Vec\"))\n",
    "results.append(run_classification(df, extract_all_features, model, \"All Features - Word2Vec\"))\n"
   ],
   "id": "d1cf5aacb47d44ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with FastText",
   "id": "9ce46d1032d1766c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load FastText word vectors\n",
    "print(\"Loading FastText model...\")\n",
    "if os.path.exists(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\"):\n",
    "    model2 = KeyedVectors.load(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\")  # faster loading\n",
    "else:\n",
    "    model2 = KeyedVectors.load_word2vec_format(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.vec\")\n",
    "    model2.save(\"pretrained_models/fasttext/wiki-news-300d-1M-subword.kv\")\n",
    "\n",
    "results.append(run_classification(df, extract_title_features, model2, \"Title Only - FastText\"))\n",
    "results.append(run_classification(df, extract_text_features, model2, \"Text Only - FastText\"))\n",
    "results.append(run_classification(df, extract_combined_features, model2, \"Title + Text - FastText\"))\n",
    "results.append(run_classification(df, extract_all_features, model2, \"All Features - FastText\"))\n"
   ],
   "id": "fa229201c16d420f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Word2Vec vs. FastText",
   "id": "67c17e491b700404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "b87a355a48490cda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Train/Evaluate",
   "id": "32e6c7bb3d43b806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_regression(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model))\n",
    "        y.append(row[\"overall\"])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbm', LGBMRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "    print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    }"
   ],
   "id": "de7974c630c509ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with Word2Vec",
   "id": "7cbb43595fdc8d0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "regression_results = []\n",
    "\n",
    "regression_results.append(run_regression(df, extract_title_features, model, \"Title Only - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_text_features, model, \"Text Only - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_combined_features, model, \"Title + Text - Word2Vec\"))\n",
    "regression_results.append(run_regression(df, extract_all_features, model, \"All Features - Word2Vec\"))"
   ],
   "id": "de09a11aec7e07b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with FastText",
   "id": "bf174bd9ca2e962b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "regression_results.append(run_regression(df, extract_title_features, model2, \"Title Only - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_text_features, model2, \"Text Only - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_combined_features, model2, \"Title + Text - FastText\"))\n",
    "regression_results.append(run_regression(df, extract_all_features, model2, \"All Features - FastText\"))"
   ],
   "id": "9b247eaf492b2ced"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Word2Vec vs. FastText",
   "id": "f3d2a2f59f2df92a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert to DataFrame\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "display(regression_results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "f9224f0685116314"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
