{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:57:06.551903Z",
     "start_time": "2025-05-29T20:57:06.546070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "# Download NLTK resources (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "97729a05ab6db2b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/i538819/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/i538819/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data and Models",
   "id": "66ad2fa480a8769e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:07:45.143406Z",
     "start_time": "2025-05-29T20:57:06.567168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CSV with all pairs\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "\n",
    "# Paths to multilingual FastText aligned vectors (.vec files)\n",
    "fasttext_model_paths = {\n",
    "    'en': 'pretrained_models/fasttext/wiki.en.align.vec',\n",
    "    'es': 'pretrained_models/fasttext/wiki.es.align.vec',\n",
    "    'de': 'pretrained_models/fasttext/wiki.de.align.vec',\n",
    "    'pl': 'pretrained_models/fasttext/wiki.pl.align.vec',\n",
    "    'tr': 'pretrained_models/fasttext/wiki.tr.align.vec',\n",
    "    'ar': 'pretrained_models/fasttext/wiki.ar.align.vec',\n",
    "    'fr': 'pretrained_models/fasttext/wiki.fr.align.vec'\n",
    "}\n",
    "\n",
    "# Load and cache gensim models\n",
    "fasttext_models = {}\n",
    "for lang, path in fasttext_model_paths.items():\n",
    "    print(f\"Loading FastText model for {lang}...\")\n",
    "    fasttext_models[lang] = KeyedVectors.load_word2vec_format(path)"
   ],
   "id": "8733782b421133d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV...\n",
      "Loading FastText model for en...\n",
      "Loading FastText model for es...\n",
      "Loading FastText model for de...\n",
      "Loading FastText model for pl...\n",
      "Loading FastText model for tr...\n",
      "Loading FastText model for ar...\n",
      "Loading FastText model for fr...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing + Embeddings",
   "id": "2c99e857b75949e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:07:45.176121Z",
     "start_time": "2025-05-29T21:07:45.173958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simple_preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    return word_tokenize(text.lower())"
   ],
   "id": "f73e3eb05b657a1d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:07:45.222427Z",
     "start_time": "2025-05-29T21:07:45.220228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def average_embedding(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ],
   "id": "aa7db70015d81b1a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extractors",
   "id": "d91b3b1d1b45dc16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:09:41.292197Z",
     "start_time": "2025-05-29T21:09:41.284740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features_lang_aware(feature_func):\n",
    "    def wrapped(row):\n",
    "        lang = row['lang1']\n",
    "        model = fasttext_models.get(lang)\n",
    "        if model is None:\n",
    "            raise ValueError(f\"No model found for language: {lang}\")\n",
    "        return feature_func(row, model)\n",
    "    return wrapped\n",
    "\n",
    "def extract_title_features(row, model_dict):\n",
    "    tokens1 = simple_preprocess(row['title1'])\n",
    "    tokens2 = simple_preprocess(row['title2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model_dict)\n",
    "    vec2 = average_embedding(tokens2, model_dict)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_text_features(row, model):\n",
    "    tokens1 = simple_preprocess(row['text1'])\n",
    "    tokens2 = simple_preprocess(row['text2'])\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_combined_features(row, model):\n",
    "    t1 = f\"{row['title1']} {row['text1']}\"\n",
    "    t2 = f\"{row['title2']} {row['text2']}\"\n",
    "    tokens1 = simple_preprocess(t1)\n",
    "    tokens2 = simple_preprocess(t2)\n",
    "\n",
    "    vec1 = average_embedding(tokens1, model)\n",
    "    vec2 = average_embedding(tokens2, model)\n",
    "\n",
    "    sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    diff = np.abs(vec1 - vec2)\n",
    "    prod = vec1 * vec2\n",
    "\n",
    "    return [sim] + diff.tolist() + prod.tolist()\n",
    "\n",
    "def extract_all_features(row, model):\n",
    "    structured_cols = ['geography', 'entities', 'time', 'narrative', 'style', 'tone']\n",
    "    # --- Title vector ---\n",
    "    tokens_title1 = simple_preprocess(row['title1'])\n",
    "    tokens_title2 = simple_preprocess(row['title2'])\n",
    "    vec_title1 = average_embedding(tokens_title1, model)\n",
    "    vec_title2 = average_embedding(tokens_title2, model)\n",
    "    sim_title = cosine_similarity([vec_title1], [vec_title2])[0][0]\n",
    "    diff_title = np.abs(vec_title1 - vec_title2)\n",
    "    prod_title = vec_title1 * vec_title2\n",
    "\n",
    "    # --- Text vector ---\n",
    "    tokens_text1 = simple_preprocess(row['text1'])\n",
    "    tokens_text2 = simple_preprocess(row['text2'])\n",
    "    vec_text1 = average_embedding(tokens_text1, model)\n",
    "    vec_text2 = average_embedding(tokens_text2, model)\n",
    "    sim_text = cosine_similarity([vec_text1], [vec_text2])[0][0]\n",
    "    diff_text = np.abs(vec_text1 - vec_text2)\n",
    "    prod_text = vec_text1 * vec_text2\n",
    "\n",
    "    # --- Structured features ---\n",
    "    structured = [row[col] for col in structured_cols]\n",
    "\n",
    "    # --- Final feature vector ---\n",
    "    return (\n",
    "        [sim_title] + diff_title.tolist() + prod_title.tolist() +\n",
    "        [sim_text] + diff_text.tolist() + prod_text.tolist() +\n",
    "        structured\n",
    "    )\n"
   ],
   "id": "53e9854a04ef11fb",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Train/Evaluate Function",
   "id": "56a121eefbc606e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:07:45.403446Z",
     "start_time": "2025-05-29T21:07:45.398542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_classification(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "\n",
    "    # Extract features\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall_classification\"])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ],
   "id": "c6235e1708dca4eb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Train/Evaluate",
   "id": "9972106b2da16e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:13:11.777072Z",
     "start_time": "2025-05-29T21:13:11.774093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_regression(df, feature_func, model, description):\n",
    "    print(f\"\\n=== Running classification on: {description} ===\")\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(feature_func(row, model) if model else feature_func(row))\n",
    "        y.append(row[\"overall\"])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "    print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": description,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    }"
   ],
   "id": "dc1640d51dcfbcda",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification with FastText",
   "id": "8e3b9f8972daaa84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:10:23.026450Z",
     "start_time": "2025-05-29T21:09:46.112625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_title_features), None, \"Title Only - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_text_features), None, \"Text Only - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_combined_features), None, \"Title + Text - Classification\"))\n",
    "results.append(run_classification(df, extract_features_lang_aware(extract_all_features), None, \"All Features - Classification\"))\n"
   ],
   "id": "d65a443e7ef95f52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on: Title Only - Classification ===\n",
      "Accuracy: 0.498\n",
      "Precision: 0.397\n",
      "Recall: 0.498\n",
      "F1 Score: 0.397\n",
      "\n",
      "=== Running classification on: Text Only - Classification ===\n",
      "Accuracy: 0.546\n",
      "Precision: 0.469\n",
      "Recall: 0.546\n",
      "F1 Score: 0.468\n",
      "\n",
      "=== Running classification on: Title + Text - Classification ===\n",
      "Accuracy: 0.526\n",
      "Precision: 0.451\n",
      "Recall: 0.526\n",
      "F1 Score: 0.445\n",
      "\n",
      "=== Running classification on: All Features - Classification ===\n",
      "Accuracy: 0.666\n",
      "Precision: 0.632\n",
      "Recall: 0.666\n",
      "F1 Score: 0.610\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression with FastText",
   "id": "9d28a46695645021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:20:11.325755Z",
     "start_time": "2025-05-29T21:13:14.291941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results.append(run_regression(df, extract_features_lang_aware(extract_title_features), None, \"Title Only - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_text_features), None, \"Text Only - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_combined_features), None, \"Title + Text - Regression\"))\n",
    "results.append(run_regression(df, extract_features_lang_aware(extract_all_features), None, \"All Features - Regression\"))"
   ],
   "id": "a3c08ace2e7f18ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on: Title Only - Regression ===\n",
      "Mean Squared Error: 0.878\n",
      "Mean Absolute Error: 0.787\n",
      "R2 Score: 0.307\n",
      "\n",
      "=== Running classification on: Text Only - Regression ===\n",
      "Mean Squared Error: 0.731\n",
      "Mean Absolute Error: 0.700\n",
      "R2 Score: 0.423\n",
      "\n",
      "=== Running classification on: Title + Text - Regression ===\n",
      "Mean Squared Error: 0.739\n",
      "Mean Absolute Error: 0.708\n",
      "R2 Score: 0.416\n",
      "\n",
      "=== Running classification on: All Features - Regression ===\n",
      "Mean Squared Error: 0.122\n",
      "Mean Absolute Error: 0.243\n",
      "R2 Score: 0.904\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FastText Classification vs. Regression",
   "id": "dbac77e435914bb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:20:11.378099Z",
     "start_time": "2025-05-29T21:20:11.355338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(by=\"Model\"))\n"
   ],
   "id": "58d11aa4ff9b344b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           Model  Accuracy  Precision    Recall  F1 Score  \\\n",
       "3  All Features - Classification  0.666058   0.632011  0.666058  0.609600   \n",
       "7      All Features - Regression       NaN        NaN       NaN       NaN   \n",
       "1     Text Only - Classification  0.545620   0.468519  0.545620  0.467616   \n",
       "5         Text Only - Regression       NaN        NaN       NaN       NaN   \n",
       "2  Title + Text - Classification  0.525547   0.450685  0.525547  0.445340   \n",
       "6      Title + Text - Regression       NaN        NaN       NaN       NaN   \n",
       "0    Title Only - Classification  0.498175   0.396775  0.498175  0.396875   \n",
       "4        Title Only - Regression       NaN        NaN       NaN       NaN   \n",
       "\n",
       "        MSE       MAE        R2  \n",
       "3       NaN       NaN       NaN  \n",
       "7  0.122117  0.243069  0.903581  \n",
       "1       NaN       NaN       NaN  \n",
       "5  0.731100  0.699769  0.422749  \n",
       "2       NaN       NaN       NaN  \n",
       "6  0.739292  0.707533  0.416281  \n",
       "0       NaN       NaN       NaN  \n",
       "4  0.878309  0.786771  0.306519  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Features - Classification</td>\n",
       "      <td>0.666058</td>\n",
       "      <td>0.632011</td>\n",
       "      <td>0.666058</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All Features - Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122117</td>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.903581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text Only - Classification</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.468519</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.467616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Text Only - Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731100</td>\n",
       "      <td>0.699769</td>\n",
       "      <td>0.422749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title + Text - Classification</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.445340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title + Text - Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739292</td>\n",
       "      <td>0.707533</td>\n",
       "      <td>0.416281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title Only - Classification</td>\n",
       "      <td>0.498175</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>0.498175</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title Only - Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878309</td>\n",
       "      <td>0.786771</td>\n",
       "      <td>0.306519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
